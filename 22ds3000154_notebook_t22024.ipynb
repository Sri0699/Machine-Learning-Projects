{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 77420,
          "databundleVersionId": 8446444,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30732,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "22ds3000154-notebook-t22024",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "Cz6a2py7eyNO"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "crime_cast_forecasting_crime_categories_path = kagglehub.competition_download('crime-cast-forecasting-crime-categories')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "6L8mr5OjeyNT"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-08-10T09:09:55.183329Z",
          "iopub.execute_input": "2024-08-10T09:09:55.183723Z",
          "iopub.status.idle": "2024-08-10T09:09:56.435175Z",
          "shell.execute_reply.started": "2024-08-10T09:09:55.183689Z",
          "shell.execute_reply": "2024-08-10T09:09:56.434001Z"
        },
        "trusted": true,
        "id": "DfPYneTBeyNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Importing Libraries"
      ],
      "metadata": {
        "id": "p7YQ-qFoeyNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "plt.style.use(\"seaborn-v0_8-notebook\")\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
        "\n",
        "# Preprocessing and Imputation required Libraries\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.feature_selection import SelectKBest,chi2\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "# Importing Models\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier,GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Importing Model selection libraries\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import validation_curve\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Importing metrics\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score,roc_auc_score,log_loss,roc_curve,auc\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import confusion_matrix,classification_report"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:10:02.015614Z",
          "iopub.execute_input": "2024-08-10T09:10:02.01618Z",
          "iopub.status.idle": "2024-08-10T09:10:04.135213Z",
          "shell.execute_reply.started": "2024-08-10T09:10:02.016146Z",
          "shell.execute_reply": "2024-08-10T09:10:04.133775Z"
        },
        "trusted": true,
        "id": "EwwKXrlVeyNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "# Suppress all warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:10:10.79113Z",
          "iopub.execute_input": "2024-08-10T09:10:10.791564Z",
          "iopub.status.idle": "2024-08-10T09:10:10.796935Z",
          "shell.execute_reply.started": "2024-08-10T09:10:10.791531Z",
          "shell.execute_reply": "2024-08-10T09:10:10.795764Z"
        },
        "trusted": true,
        "id": "JilmEi1leyNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Columns Description:\n",
        "* Location: Street address of the crime incident.\n",
        "* Cross_Street: Cross street of the rounded address.\n",
        "* Latitude: Latitude coordinates of the crime incident.\n",
        "* Longitude: Longitude coordinates of the crime incident.\n",
        "* Date_Reported: Date the incident was reported.\n",
        "* Date_Occurred: Date the incident occurred.\n",
        "* Time_Occurred: Time the incident occurred in 24-hour military time.\n",
        "* Area_ID: LAPD's Geographic Area number.\n",
        "* Area_Name: Name designation of the LAPD Geographic Area.\n",
        "* Reporting_District_no: Reporting district number.\n",
        "* Part 1-2: Crime classification.\n",
        "* Modus_Operandi: Activities associated with the suspect.\n",
        "* Victim_Age: Age of the victim.\n",
        "* Victim_Sex: Gender of the victim.\n",
        "* Victim_Descent: Descent code of the victim.\n",
        "* Premise_Code: Premise code indicating the location of the crime.\n",
        "* Premise_Description: Description of the premise code.\n",
        "* Weapon_Used_Code: Weapon code indicating the type of weapon used.\n",
        "* Weapon_Description: Description of the weapon code.\n",
        "* Status: Status of the case.\n",
        "* Status_Description: Description of the status code.\n",
        "* Crime_Category: The category of the crime (Target Variable)"
      ],
      "metadata": {
        "id": "SSX95NjteyNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# where ever random numbers to be generated, setting this seed helps to generate same random numbers\n",
        "np.random.seed(219)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:10:17.40281Z",
          "iopub.execute_input": "2024-08-10T09:10:17.404092Z",
          "iopub.status.idle": "2024-08-10T09:10:17.408941Z",
          "shell.execute_reply.started": "2024-08-10T09:10:17.404055Z",
          "shell.execute_reply": "2024-08-10T09:10:17.407771Z"
        },
        "trusted": true,
        "id": "K-CWajn4eyNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data"
      ],
      "metadata": {
        "id": "Wsiydn7feyNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/kaggle/input/crime-cast-forecasting-crime-categories/train.csv')\n",
        "test_df =  pd.read_csv('/kaggle/input/crime-cast-forecasting-crime-categories/test.csv')\n",
        "sample =   pd.read_csv('/kaggle/input/crime-cast-forecasting-crime-categories/sample.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:10:20.790451Z",
          "iopub.execute_input": "2024-08-10T09:10:20.791314Z",
          "iopub.status.idle": "2024-08-10T09:10:21.053501Z",
          "shell.execute_reply.started": "2024-08-10T09:10:20.791276Z",
          "shell.execute_reply": "2024-08-10T09:10:21.052235Z"
        },
        "trusted": true,
        "id": "rL2tzWLveyNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis(EDA)"
      ],
      "metadata": {
        "id": "iWd-aYRPeyNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the first five records of Training Data Frame\n",
        "train_df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:10:26.267867Z",
          "iopub.execute_input": "2024-08-10T09:10:26.268275Z",
          "iopub.status.idle": "2024-08-10T09:10:26.31741Z",
          "shell.execute_reply.started": "2024-08-10T09:10:26.268243Z",
          "shell.execute_reply": "2024-08-10T09:10:26.316379Z"
        },
        "trusted": true,
        "id": "zA41avN_eyNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets check the shape of Training Data Frame\n",
        "train_df.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:10:33.123413Z",
          "iopub.execute_input": "2024-08-10T09:10:33.124203Z",
          "iopub.status.idle": "2024-08-10T09:10:33.131595Z",
          "shell.execute_reply.started": "2024-08-10T09:10:33.124166Z",
          "shell.execute_reply": "2024-08-10T09:10:33.130361Z"
        },
        "trusted": true,
        "id": "KXuChxy2eyNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:10:35.545602Z",
          "iopub.execute_input": "2024-08-10T09:10:35.546041Z",
          "iopub.status.idle": "2024-08-10T09:10:35.599188Z",
          "shell.execute_reply.started": "2024-08-10T09:10:35.546006Z",
          "shell.execute_reply": "2024-08-10T09:10:35.598071Z"
        },
        "trusted": true,
        "id": "49jEWjhDeyNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the inputs from the ***train_df.info()*** method and the feature description provided by the Competetion, the segementation of the features is as follow:\n",
        "\n",
        "**Categorical Features**:\n",
        "{Location, Cross_Street, Area_ID, Area_Name, Reporting_District_no,\n",
        "Part 1-2,  Modus_Operandi,  Victim_Sex, Victim_Descent,  Premise_Code,  Premise_Description, Weapon_Used_Code, Weapon_Description, Status, Status_Description, Crime_Category}\n",
        "\n",
        "**Numerical Features**: {Latitude, Longitude, Victim_Age, Time_Occurred}\n",
        "\n",
        "**Observations**\n",
        "\n",
        "1. In the above list there are some features which are containing float values like : Reporting_District_no, Part 1-2, Area_ID, Weapon_Used_Code.\n",
        "   But these features are still categorical in nature because of the given description.\n",
        "  \n",
        "2. Also some of the features are repeatative by providing the same information.\n",
        "\n",
        "Example: Latitude and Longitude can actually help in providing the information about particular Location, but the same information can be found in Location and Cross_Street fields also.\n",
        "\n",
        "3. The Target Variable 'Crime Category' is  categorical in nature, thus a classification problem.\n"
      ],
      "metadata": {
        "id": "21NO2_JEeyNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for Null Values in the train_df data frame.\n",
        "\n",
        "train_df.isna().sum()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:10:42.385997Z",
          "iopub.execute_input": "2024-08-10T09:10:42.386426Z",
          "iopub.status.idle": "2024-08-10T09:10:42.424434Z",
          "shell.execute_reply.started": "2024-08-10T09:10:42.386393Z",
          "shell.execute_reply": "2024-08-10T09:10:42.422977Z"
        },
        "trusted": true,
        "id": "LdG3TGrVeyNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation**:  The below features have more than 50% null values in the training dataset.\n",
        "\n",
        "1. Cross_Street\n",
        "\n",
        "2. Weapon_Used_Code\n",
        "\n",
        "3. Weapon_Description  "
      ],
      "metadata": {
        "id": "iEtYP9QueyNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the unique values in target variable\n",
        "\n",
        "train_df['Crime_Category'].unique()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:10:47.198411Z",
          "iopub.execute_input": "2024-08-10T09:10:47.198826Z",
          "iopub.status.idle": "2024-08-10T09:10:47.209531Z",
          "shell.execute_reply.started": "2024-08-10T09:10:47.198793Z",
          "shell.execute_reply": "2024-08-10T09:10:47.208233Z"
        },
        "trusted": true,
        "id": "dtIqiPHOeyNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets check the type of target variable\n",
        "\n",
        "from sklearn.utils.multiclass import type_of_target\n",
        "\n",
        "y= train_df['Crime_Category']\n",
        "\n",
        "print(type_of_target(y))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:10:52.856784Z",
          "iopub.execute_input": "2024-08-10T09:10:52.857203Z",
          "iopub.status.idle": "2024-08-10T09:10:52.885502Z",
          "shell.execute_reply.started": "2024-08-10T09:10:52.857169Z",
          "shell.execute_reply": "2024-08-10T09:10:52.884327Z"
        },
        "trusted": true,
        "id": "2IHslvFReyNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the target variable - 'Crime_Category' using Count Plot Chart\n",
        "\n",
        "sns.countplot(x=\"Crime_Category\", data=train_df) # helps in giving the frequency of each crime category in Training Data Frame.\n",
        "\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels if needed\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:10:58.346211Z",
          "iopub.execute_input": "2024-08-10T09:10:58.347248Z",
          "iopub.status.idle": "2024-08-10T09:10:58.695632Z",
          "shell.execute_reply.started": "2024-08-10T09:10:58.34721Z",
          "shell.execute_reply": "2024-08-10T09:10:58.694449Z"
        },
        "trusted": true,
        "id": "-bnWLnEreyNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing Crime category distribution by Area_Name using Count Plot Chart.\n",
        "\n",
        "sns.countplot(x='Area_Name', hue='Crime_Category', data=train_df)\n",
        "\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "plt.title('Breakdown of Crime distribution across different Areas')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:11:04.225857Z",
          "iopub.execute_input": "2024-08-10T09:11:04.226655Z",
          "iopub.status.idle": "2024-08-10T09:11:05.176763Z",
          "shell.execute_reply.started": "2024-08-10T09:11:04.226619Z",
          "shell.execute_reply": "2024-08-10T09:11:05.175492Z"
        },
        "trusted": true,
        "id": "7olkfkBGeyNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation**\n",
        "\n",
        "1. Property Crime seems to be the most frequent type of crime to be committed across all 21 areas. With the Pacific area having the highest crimes committed by Area.\n",
        "\n",
        "2. Foothill and Hollenback having some of the lowest crimes committed by Area."
      ],
      "metadata": {
        "id": "uawNz6pieyNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the Crime Category distribution by Part 1-2 feature using Count Plot Chart\n",
        "\n",
        "sns.countplot(x='Part 1-2', hue='Crime_Category', data=train_df)\n",
        "\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "plt.title('Crime Category distribution by Part 1-2')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:11:10.173729Z",
          "iopub.execute_input": "2024-08-10T09:11:10.174162Z",
          "iopub.status.idle": "2024-08-10T09:11:10.570775Z",
          "shell.execute_reply.started": "2024-08-10T09:11:10.174124Z",
          "shell.execute_reply": "2024-08-10T09:11:10.56964Z"
        },
        "trusted": true,
        "id": "59e8NpYFeyNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation**:\n",
        "1. The above plot provides an inference about the relation between Part 1-2 feature and the Target Variable.\n",
        "\n",
        "2. In Part 1-2 feature the crimes which have been assigned with class 2 contain all the categories of crime.\n",
        "\n",
        "3. While the crimes assigned to class 1 contain property,violent and crimes against public order; with property crimes being the predominant crime category."
      ],
      "metadata": {
        "id": "Cjeii6xleyNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imputation**"
      ],
      "metadata": {
        "id": "oenUSZHieyNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# null values are filled with constant \"0\" in train_df\n",
        "\n",
        "train_df['Weapon_Used_Code'] = train_df['Weapon_Used_Code'].fillna(0)\n",
        "\n",
        "# null values are filled with constant \"0\" in test_df\n",
        "\n",
        "test_df['Weapon_Used_Code'] = test_df['Weapon_Used_Code'].fillna(0)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:11:18.809398Z",
          "iopub.execute_input": "2024-08-10T09:11:18.810365Z",
          "iopub.status.idle": "2024-08-10T09:11:18.818549Z",
          "shell.execute_reply.started": "2024-08-10T09:11:18.810302Z",
          "shell.execute_reply": "2024-08-10T09:11:18.81738Z"
        },
        "trusted": true,
        "id": "EnQhB4TCeyNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Understanding the Relationship between Numerical Features in Training Data Frame using Pairplot\n",
        "\n",
        "sns.pairplot(train_df,\n",
        "\n",
        "             diag_kind='kde',# Use kernel density estimation for diagonal plots\n",
        "\n",
        "             kind='scatter')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:11:25.216233Z",
          "iopub.execute_input": "2024-08-10T09:11:25.217219Z",
          "iopub.status.idle": "2024-08-10T09:11:56.33399Z",
          "shell.execute_reply.started": "2024-08-10T09:11:25.217181Z",
          "shell.execute_reply": "2024-08-10T09:11:56.332616Z"
        },
        "trusted": true,
        "id": "D3j395FoeyNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations**\n",
        "\n",
        "1. The above pair plot displays a high density amongst most of the numerical feature variables and lot of sub populations are revealed within some of the features like Part 1-2.\n",
        "\n",
        "2. While the density/histogram plots presented on the diagonal line suggest that the feature variables might belong to Gaussian family of distributions.\n",
        "\n",
        "3. Most pairplots between the features hint at a potential redundancy indicating a low variance, which means such features can be removed as they do not increase the predictive power of the model.    "
      ],
      "metadata": {
        "id": "hb2-gy3keyNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "ON3WEwVPeyNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transformations to be done feature wise\n",
        "---------------------------\n",
        "* Loction is ignored as it is captured in Latitude and Longitude\n",
        "* Cross_Street is ignored as it is captured in Latitude and Longitude\n",
        "* Latitude MinMaxScalar\n",
        "* Longitude MinMaxScalar\n",
        "* Date_Reported to be modified as Date Object\n",
        "* Date_Occurred to be modified as Date Object and Difference between two dates (\"Time_Difference\") is calculated\n",
        "* Time_Difference MinMaxScalar\n",
        "* Time_Occurred MinMaxScalar\n",
        "* Area_ID OneHotEncoding\n",
        "* Area_Name is ignored, as it is captured in 'Area_ID'\n",
        "* Reporting_District_no OneHot encoding\n",
        "* \"Part 1-2\" no transformation required\n",
        "* Separate Modus_Operandi column values into 10 different columns and if the activity is present it will have the code, otherwise \"0\"\n",
        "* Victim_Age Min Max Scaling\n",
        "* Victim_Sex, replace 'NaN' with 'U' (Unknown) and do OneHot encoding\n",
        "* Victim_Descent, replace 'NaN' with 'N'(None) and do OneHot encoding\n",
        "* Premise_Code , OneHot encoding\n",
        "* Weapon_Used_Code , replace 'nan' with 0 and d OneHot encoding\n",
        "* Status , OneHot encoding\n",
        "* Ignore \"Premise_Description\", \"Weapon_Description\", \"Status_Description\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QGp2hrIqeyNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping Target variable from train_df\n",
        "\n",
        "X = train_df.drop(['Crime_Category'], axis = 'columns') # Feature Matrix\n",
        "\n",
        "y = train_df['Crime_Category']  # Label Vector"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:12:10.285454Z",
          "iopub.execute_input": "2024-08-10T09:12:10.285996Z",
          "iopub.status.idle": "2024-08-10T09:12:10.295689Z",
          "shell.execute_reply.started": "2024-08-10T09:12:10.285962Z",
          "shell.execute_reply": "2024-08-10T09:12:10.294461Z"
        },
        "trusted": true,
        "id": "hRg-QhjZeyNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['Modus_Operandi'].head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:12:12.780371Z",
          "iopub.execute_input": "2024-08-10T09:12:12.780797Z",
          "iopub.status.idle": "2024-08-10T09:12:12.790232Z",
          "shell.execute_reply.started": "2024-08-10T09:12:12.780764Z",
          "shell.execute_reply": "2024-08-10T09:12:12.789079Z"
        },
        "trusted": true,
        "id": "ib5NcI2MeyNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* From looking at the samples in Modus_Operandi feature, I notice that feature consists of numerical codes but are of object type (string type).\n",
        "* Also in each record the length of the string varies with the highest being 10, hence splitting the Modus_Operandi feature into 10 new columns, to accomodate each code.  "
      ],
      "metadata": {
        "id": "e4eFYuO6eyNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Modus_operandi column into 10 separate columns in train_df\n",
        "\n",
        "train_df[['Modus1', 'Modus2', 'Modus3','Modus4', 'Modus5', 'Modus6','Modus7', 'Modus8', 'Modus9','Modus10']] = train_df['Modus_Operandi'].str.split(' ', expand=True, n=9)\n",
        "\n",
        "# Imputing the missing values in the 10 new columns with 0 in train_df\n",
        "\n",
        "train_df[['Modus1', 'Modus2', 'Modus3','Modus4', 'Modus5', 'Modus6','Modus7', 'Modus8', 'Modus9','Modus10']] = train_df[['Modus1', 'Modus2', 'Modus3','Modus4', 'Modus5', 'Modus6','Modus7', 'Modus8', 'Modus9','Modus10']].fillna('0').astype(int)\n",
        "\n",
        "# Splitting the Modus_operandi column into 10 separate columns in test_df\n",
        "\n",
        "test_df[['Modus1', 'Modus2', 'Modus3','Modus4', 'Modus5', 'Modus6','Modus7', 'Modus8', 'Modus9','Modus10']] = test_df['Modus_Operandi'].str.split(' ', expand=True, n=9)\n",
        "\n",
        "# Imputing the missing values in the 10 new columns with 0 in test_df\n",
        "\n",
        "test_df[['Modus1', 'Modus2', 'Modus3','Modus4', 'Modus5', 'Modus6','Modus7', 'Modus8', 'Modus9','Modus10']] = test_df[['Modus1', 'Modus2', 'Modus3','Modus4', 'Modus5', 'Modus6','Modus7', 'Modus8', 'Modus9','Modus10']].fillna('0').astype(int)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:12:17.574602Z",
          "iopub.execute_input": "2024-08-10T09:12:17.575787Z",
          "iopub.status.idle": "2024-08-10T09:12:17.736461Z",
          "shell.execute_reply.started": "2024-08-10T09:12:17.575741Z",
          "shell.execute_reply": "2024-08-10T09:12:17.735325Z"
        },
        "trusted": true,
        "id": "HS8fM2KNeyNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the Date_Reported column into datetime object.\n",
        "\n",
        "train_df['Date_Reported'] = pd.to_datetime(train_df['Date_Reported']) # Train Data Frame\n",
        "\n",
        "test_df['Date_Reported'] = pd.to_datetime(test_df['Date_Reported']) # Test Data Frame\n",
        "\n",
        "# Converting the Date_Occured column into datetime object.\n",
        "\n",
        "train_df['Date_Occurred'] = pd.to_datetime(train_df['Date_Occurred']) # Train Data Frame\n",
        "\n",
        "test_df['Date_Occurred'] = pd.to_datetime(test_df['Date_Occurred'])  # Test Data Frame\n",
        "\n",
        "# Creating a new column to capture the time difference.\n",
        "\n",
        "train_df.loc[:,'Time_Difference'] = (train_df['Date_Reported'] - train_df['Date_Occurred']).dt.days # Train Data Frame\n",
        "\n",
        "test_df.loc[:,'Time_Difference'] = (test_df['Date_Reported'] - test_df['Date_Occurred']).dt.days   # Test Data Frame"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:12:22.511148Z",
          "iopub.execute_input": "2024-08-10T09:12:22.51179Z",
          "iopub.status.idle": "2024-08-10T09:12:22.832651Z",
          "shell.execute_reply.started": "2024-08-10T09:12:22.511755Z",
          "shell.execute_reply": "2024-08-10T09:12:22.831573Z"
        },
        "trusted": true,
        "id": "FuRe8-UXeyNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping Unrequired Columns in both Train and Test Data Frames to decrease redundancy\n",
        "\n",
        "train_df = train_df.drop([\"Location\", \"Cross_Street\", \"Area_Name\",\"Date_Reported\", \"Date_Occurred\", \"Modus_Operandi\", \"Premise_Description\", \"Weapon_Description\", \"Status_Description\",\"Crime_Category\"], axis=1)\n",
        "\n",
        "test_df = test_df.drop([\"Location\", \"Cross_Street\", \"Area_Name\", \"Date_Reported\", \"Date_Occurred\", \"Modus_Operandi\", \"Premise_Description\", \"Weapon_Description\", \"Status_Description\"], axis=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:12:24.985685Z",
          "iopub.execute_input": "2024-08-10T09:12:24.986542Z",
          "iopub.status.idle": "2024-08-10T09:12:24.999405Z",
          "shell.execute_reply.started": "2024-08-10T09:12:24.986502Z",
          "shell.execute_reply": "2024-08-10T09:12:24.99822Z"
        },
        "trusted": true,
        "id": "kHLJ3MRqeyNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_train_test_df=pd.concat([train_df,test_df], ignore_index=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:12:31.675206Z",
          "iopub.execute_input": "2024-08-10T09:12:31.67561Z",
          "iopub.status.idle": "2024-08-10T09:12:31.687363Z",
          "shell.execute_reply.started": "2024-08-10T09:12:31.675581Z",
          "shell.execute_reply": "2024-08-10T09:12:31.686176Z"
        },
        "trusted": true,
        "id": "2Y6v1ixreyNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note** :\n",
        "\n",
        "Due to OneHotEncoding there will be mismatch in the number of dummy features generated in training and test data sets,\n",
        "\n",
        "which will be causing issues when submitting the mode."
      ],
      "metadata": {
        "id": "HcC65mujeyNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessing_pipeline = ColumnTransformer(transformers = [('MinMax',MinMaxScaler(),['Time_Difference','Time_Occurred','Victim_Age','Latitude','Longitude']),\n",
        "                                                                ('StanScalar',StandardScaler(),['Modus1', 'Modus2', 'Modus3','Modus4', 'Modus5', 'Modus6','Modus7', 'Modus8', 'Modus9','Modus10']),\n",
        "                                                           ('VicGen', Pipeline([('imputer',SimpleImputer(missing_values=np.nan, strategy='constant', fill_value='U')),('encoder',OneHotEncoder(handle_unknown='ignore'))]),['Victim_Sex']),\n",
        "   ('VicDes',Pipeline([('imputer',SimpleImputer(missing_values=np.nan, strategy='constant', fill_value='N')),('encoder',OneHotEncoder(handle_unknown='ignore'))]),['Victim_Descent']),\n",
        "   ('encoder',OneHotEncoder(handle_unknown='ignore'),['Area_ID','Reporting_District_no','Premise_Code','Weapon_Used_Code','Status'])],remainder = 'passthrough')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:12:34.458334Z",
          "iopub.execute_input": "2024-08-10T09:12:34.458792Z",
          "iopub.status.idle": "2024-08-10T09:12:34.469266Z",
          "shell.execute_reply.started": "2024-08-10T09:12:34.458758Z",
          "shell.execute_reply": "2024-08-10T09:12:34.46781Z"
        },
        "trusted": true,
        "id": "nMVJVi8BeyNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transformed = preprocessing_pipeline.fit_transform(train_df) # Validation Set\n",
        "\n",
        "combined_train_test = preprocessing_pipeline.fit_transform(combined_train_test_df) # Original Train and Test combined Set"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:12:41.230592Z",
          "iopub.execute_input": "2024-08-10T09:12:41.231443Z",
          "iopub.status.idle": "2024-08-10T09:12:41.455909Z",
          "shell.execute_reply.started": "2024-08-10T09:12:41.231406Z",
          "shell.execute_reply": "2024-08-10T09:12:41.454717Z"
        },
        "trusted": true,
        "id": "hrQkpuGLeyNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Original Training and Testing sets in encoded format\n",
        "\n",
        "train_encoded = combined_train_test[:len(train_df)]\n",
        "\n",
        "test_encoded = combined_train_test[len(train_df):]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:12:43.696844Z",
          "iopub.execute_input": "2024-08-10T09:12:43.697309Z",
          "iopub.status.idle": "2024-08-10T09:12:43.712578Z",
          "shell.execute_reply.started": "2024-08-10T09:12:43.697236Z",
          "shell.execute_reply": "2024-08-10T09:12:43.711357Z"
        },
        "trusted": true,
        "id": "BjMrRtqIeyNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the train_transformed into Train and Validation sets.\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_transformed, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:12:49.13862Z",
          "iopub.execute_input": "2024-08-10T09:12:49.139026Z",
          "iopub.status.idle": "2024-08-10T09:12:49.154707Z",
          "shell.execute_reply.started": "2024-08-10T09:12:49.138997Z",
          "shell.execute_reply": "2024-08-10T09:12:49.153509Z"
        },
        "trusted": true,
        "id": "9eT9nb-7eyNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering\n",
        "\n",
        "## 1. Feature Extraction using PCA"
      ],
      "metadata": {
        "id": "aWr8Tk0ieyNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train.toarray())\n",
        "\n",
        "pca = PCA(n_components=0.25)\n",
        "pca.fit(X_train_scaled)\n",
        "\n",
        "X_train_pca = pca.transform(X_train_scaled)\n",
        "X_val_scaled = scaler.transform(X_val.toarray())\n",
        "X_val_pca = pca.transform(X_val_scaled)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:12:55.38278Z",
          "iopub.execute_input": "2024-08-10T09:12:55.383208Z",
          "iopub.status.idle": "2024-08-10T09:13:03.729878Z",
          "shell.execute_reply.started": "2024-08-10T09:12:55.383176Z",
          "shell.execute_reply": "2024-08-10T09:13:03.728312Z"
        },
        "trusted": true,
        "id": "EO0kxhDGeyNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Feature Selection using SelectKBest"
      ],
      "metadata": {
        "id": "AJ6etzs9eyNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select K best features\n",
        "\n",
        "selector = SelectKBest(score_func=mutual_info_classif, k=1000)\n",
        "selector.fit(X_train, y_train)\n",
        "\n",
        "# Transform both training and validation sets\n",
        "X_train_selected = selector.transform(X_train)\n",
        "X_val_selected = selector.transform(X_val)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:13:09.252356Z",
          "iopub.execute_input": "2024-08-10T09:13:09.25352Z",
          "iopub.status.idle": "2024-08-10T09:13:48.167901Z",
          "shell.execute_reply.started": "2024-08-10T09:13:09.253484Z",
          "shell.execute_reply": "2024-08-10T09:13:48.166552Z"
        },
        "trusted": true,
        "id": "V5vaM1NMeyNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Label Encoding\n",
        "\n",
        "y_reshaped = y.values.reshape(-1,1)  # Reshaping Original Label\n",
        "\n",
        "y_train_reshaped = y_train.values.reshape(-1, 1) # Reshaping Train Label\n",
        "\n",
        "y_val_reshaped = y_val.values.reshape(-1, 1) # Reshaping Validation Label\n",
        "\n",
        "y_encoder = OneHotEncoder(sparse_output=False)  # Creating OneHotEncoder instance\n",
        "\n",
        "y_transformed = y_encoder.fit_transform(y_reshaped) # Fitting Encoder on Original Label\n",
        "\n",
        "y_train_transformed = y_encoder.fit_transform(y_train_reshaped) # Fitting Encoder on Train Label\n",
        "\n",
        "y_val_transformed = y_encoder.fit_transform(y_val_reshaped) # Fitting Encoder on Validation Label\n",
        "\n",
        "y_single_label = np.argmax(y_transformed, axis=1) # Transformed Orginal Label\n",
        "\n",
        "y_train_single_label = np.argmax(y_train_transformed, axis=1) # Transformed Train Label\n",
        "\n",
        "y_val_single_label = np.argmax(y_val_transformed, axis=1) # Transformed Validation Label"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:13:50.088554Z",
          "iopub.execute_input": "2024-08-10T09:13:50.089003Z",
          "iopub.status.idle": "2024-08-10T09:13:50.117399Z",
          "shell.execute_reply.started": "2024-08-10T09:13:50.088937Z",
          "shell.execute_reply": "2024-08-10T09:13:50.11623Z"
        },
        "trusted": true,
        "id": "SH9IjfnheyNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODELS\n",
        "\n",
        "1. Logistic Regression\n",
        "\n",
        "2. KNN Model\n",
        "\n",
        "3. Decission Tree Classifier\n",
        "\n",
        "4. Bagging Classifier Model\n",
        "\n",
        "5. Multi Layer Perceptron (MLP)\n",
        "\n",
        "6. Gradient Boosting Classifier (Best scoring model - Final submission for competition)"
      ],
      "metadata": {
        "id": "lk84cp16eyNn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------"
      ],
      "metadata": {
        "id": "gKc7AkRIeyNn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "hdEuA32seyNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameter tuning using Random Search CV\n",
        "param_dist = {'solver': ['liblinear', 'newton-cg'],\n",
        "              'C': np.logspace(-4, 4, 5)}  # Logarithmic distribution\n",
        "reg_model = LogisticRegression()\n",
        "# Create the RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(reg_model, param_dist, n_iter=1000, cv=5)\n",
        "\n",
        "# Fit the random search to the training data\n",
        "\n",
        "random_search.fit(X_train, y_train_single_label)\n",
        "\n",
        "best_model = random_search.best_estimator_\n",
        "best_params = random_search.best_params_\n",
        "best_score = random_search.best_score_\n",
        "\n",
        "print(best_params)\n",
        "print(best_model)\n",
        "print(best_score)"
      ],
      "metadata": {
        "trusted": true,
        "id": "fmm6JQi1eyNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Result*** :\n",
        "\n",
        "After conducting RandomSearchCV on the Logistic Regression model, these were the best parameters :\n",
        "\n",
        "{penalty=\"l2\", C=1, multi_class='ovr', solver='newton-cg', max_iter=2000}"
      ],
      "metadata": {
        "id": "ZGVhmNWWeyNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation Metrics without Feature Engineering\n",
        "\n",
        "reg_model1 = LogisticRegression(penalty=\"l2\", C=1, multi_class='ovr', solver='newton-cg', max_iter=2000)\n",
        "\n",
        "reg_model1.fit(X_train, y_train_single_label)\n",
        "\n",
        "pred_Logreg = reg_model1.predict(X_val)\n",
        "\n",
        "# Get unique original labels\n",
        "original_labels = np.unique(y_train)\n",
        "\n",
        "# Create mapping\n",
        "label_mapping = {i: label for i, label in enumerate(original_labels)}\n",
        "\n",
        "# Convert predicted indices to original labels\n",
        "y_pred_original = [label_mapping[pred] for pred in pred_Logreg]\n",
        "\n",
        "\n",
        "accuracy_Log = accuracy_score(y_val, y_pred_original)\n",
        "precision_Log = precision_score(y_val, y_pred_original,average='weighted')\n",
        "recall_Log = recall_score(y_val, y_pred_original,average='weighted')\n",
        "f1_Log = f1_score(y_val, y_pred_original,average='weighted')\n",
        "\n",
        "conf_matrix = confusion_matrix(y_val, y_pred_original)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_Log)\n",
        "print(\"Precision:\", precision_Log)\n",
        "print(\"Recall:\", recall_Log)\n",
        "print(\"F1-score:\",f1_Log)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:14:20.708887Z",
          "iopub.execute_input": "2024-08-10T09:14:20.709292Z",
          "iopub.status.idle": "2024-08-10T09:14:25.657945Z",
          "shell.execute_reply.started": "2024-08-10T09:14:20.709261Z",
          "shell.execute_reply": "2024-08-10T09:14:25.656779Z"
        },
        "trusted": true,
        "id": "ltoBLUdneyNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation Metrics with Feature Engineering (PCA)\n",
        "\n",
        "reg_model2 = LogisticRegression(penalty=\"l2\", C=1, multi_class='ovr', solver='newton-cg', max_iter=2000)\n",
        "\n",
        "reg_model2.fit(X_train_pca, y_train_single_label)\n",
        "\n",
        "pred_Logreg = reg_model2.predict(X_val_pca)\n",
        "\n",
        "# Get unique original labels\n",
        "original_labels = np.unique(y_train)\n",
        "\n",
        "# Create mapping\n",
        "label_mapping = {i: label for i, label in enumerate(original_labels)}\n",
        "\n",
        "# Convert predicted indices to original labels\n",
        "y_pred_original = [label_mapping[pred] for pred in pred_Logreg]\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_val, y_pred_original)\n",
        "precision = precision_score(y_val, y_pred_original,average='weighted')\n",
        "recall = recall_score(y_val, y_pred_original,average='weighted')\n",
        "f1 = f1_score(y_val, y_pred_original,average='weighted')\n",
        "\n",
        "conf_matrix = confusion_matrix(y_val, y_pred_original)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\",f1)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:14:39.768269Z",
          "iopub.execute_input": "2024-08-10T09:14:39.768731Z",
          "iopub.status.idle": "2024-08-10T09:14:49.284259Z",
          "shell.execute_reply.started": "2024-08-10T09:14:39.768697Z",
          "shell.execute_reply": "2024-08-10T09:14:49.283167Z"
        },
        "trusted": true,
        "id": "03JMNyLreyNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation Metrics with Feature Engineering (SelectKBest)\n",
        "\n",
        "reg_model3 = LogisticRegression(penalty=\"l2\", C=1, multi_class='ovr', solver='newton-cg', max_iter=2000)\n",
        "\n",
        "reg_model3.fit(X_train_selected, y_train_single_label)\n",
        "\n",
        "pred_Logreg = reg_model3.predict(X_val_selected)\n",
        "\n",
        "# Get unique original labels\n",
        "original_labels = np.unique(y_train)\n",
        "\n",
        "# Create mapping\n",
        "label_mapping = {i: label for i, label in enumerate(original_labels)}\n",
        "\n",
        "# Convert predicted indices to original labels\n",
        "y_pred_original = [label_mapping[pred] for pred in pred_Logreg]\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_val, y_pred_original)\n",
        "precision = precision_score(y_val, y_pred_original,average='weighted')\n",
        "recall = recall_score(y_val, y_pred_original,average='weighted')\n",
        "f1 = f1_score(y_val, y_pred_original,average='weighted')\n",
        "\n",
        "conf_matrix = confusion_matrix(y_val, y_pred_original)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\",f1)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:14:54.661628Z",
          "iopub.execute_input": "2024-08-10T09:14:54.662135Z",
          "iopub.status.idle": "2024-08-10T09:14:59.634583Z",
          "shell.execute_reply.started": "2024-08-10T09:14:54.662099Z",
          "shell.execute_reply": "2024-08-10T09:14:59.633543Z"
        },
        "trusted": true,
        "id": "P5JSKLjfeyNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------------------------------------------------"
      ],
      "metadata": {
        "id": "DzwoKbjKeyNo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN Model"
      ],
      "metadata": {
        "id": "QC1JfYTYeyNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameter tuning using Random Search CV\n",
        "\n",
        "param_grid = {\n",
        "    'n_neighbors': [9, 11, 15],\n",
        "    'metric': ['euclidean', 'manhattan']\n",
        "}\n",
        "knn_model = KNeighborsClassifier()\n",
        "random_search = RandomizedSearchCV(knn_model, param_grid, cv=5, n_iter=100)\n",
        "random_search.fit(X_train, y_train_single_label)\n",
        "\n",
        "best_random_params = random_search.best_params_\n",
        "best_random_score = random_search.best_score_"
      ],
      "metadata": {
        "trusted": true,
        "id": "uZKujRPaeyNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation Metrics without Feature Engineering\n",
        "\n",
        "knn_model =  KNeighborsClassifier(n_neighbors=15, metric = 'euclidean')\n",
        "knn_model.fit(X_train, y_train_single_label)\n",
        "y_pred_knn = knn_model.predict(X_val)\n",
        "\n",
        "# Get unique original labels\n",
        "original_labels = np.unique(y_train)\n",
        "\n",
        "# Create mapping\n",
        "label_mapping = {i: label for i, label in enumerate(original_labels)}\n",
        "\n",
        "# Convert predicted indices to original labels\n",
        "y_pred_original = [label_mapping[pred] for pred in y_pred_knn]\n",
        "\n",
        "\n",
        "accuracy_knn = accuracy_score(y_val, y_pred_original)\n",
        "precision_knn = precision_score(y_val, y_pred_original,average='weighted')\n",
        "recall_knn = recall_score(y_val, y_pred_original,average='weighted')\n",
        "f1_knn = f1_score(y_val, y_pred_original,average='weighted')\n",
        "\n",
        "conf_matrix = confusion_matrix(y_val, y_pred_original)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_knn)\n",
        "print(\"Precision:\", precision_knn)\n",
        "print(\"Recall:\", recall_knn)\n",
        "print(\"F1-score:\",f1_knn)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:15:11.222911Z",
          "iopub.execute_input": "2024-08-10T09:15:11.223321Z",
          "iopub.status.idle": "2024-08-10T09:15:34.464499Z",
          "shell.execute_reply.started": "2024-08-10T09:15:11.223291Z",
          "shell.execute_reply": "2024-08-10T09:15:34.463231Z"
        },
        "trusted": true,
        "id": "wGHotgOqeyNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation Metrics with Feature Engineering (PCA)\n",
        "\n",
        "knn_model =  KNeighborsClassifier(n_neighbors=15, metric = 'euclidean')\n",
        "knn_model.fit(X_train_pca, y_train_single_label)\n",
        "y_pred_knn = knn_model.predict(X_val_pca)\n",
        "\n",
        "# Get unique original labels\n",
        "original_labels = np.unique(y_train)\n",
        "\n",
        "# Create mapping\n",
        "label_mapping = {i: label for i, label in enumerate(original_labels)}\n",
        "\n",
        "# Convert predicted indices to original labels\n",
        "y_pred_original = [label_mapping[pred] for pred in y_pred_knn]\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_val, y_pred_original)\n",
        "precision = precision_score(y_val, y_pred_original,average='weighted')\n",
        "recall = recall_score(y_val, y_pred_original,average='weighted')\n",
        "f1 = f1_score(y_val, y_pred_original,average='weighted')\n",
        "\n",
        "conf_matrix = confusion_matrix(y_val, y_pred_original)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\",f1)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)"
      ],
      "metadata": {
        "trusted": true,
        "id": "gbHK6xyHeyNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation Metrics with Feature Engineering (SelectKBest)\n",
        "\n",
        "knn_model =  KNeighborsClassifier(n_neighbors=15, metric = 'euclidean')\n",
        "knn_model.fit(X_train_selected, y_train_single_label)\n",
        "y_pred_knn = knn_model.predict(X_val_selected)\n",
        "\n",
        "# Get unique original labels\n",
        "original_labels = np.unique(y_train)\n",
        "\n",
        "# Create mapping\n",
        "label_mapping = {i: label for i, label in enumerate(original_labels)}\n",
        "\n",
        "# Convert predicted indices to original labels\n",
        "y_pred_original = [label_mapping[pred] for pred in y_pred_knn]\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_val, y_pred_original)\n",
        "precision = precision_score(y_val, y_pred_original,average='weighted')\n",
        "recall = recall_score(y_val, y_pred_original,average='weighted')\n",
        "f1 = f1_score(y_val, y_pred_original,average='weighted')\n",
        "\n",
        "conf_matrix = confusion_matrix(y_val, y_pred_original)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\",f1)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)"
      ],
      "metadata": {
        "trusted": true,
        "id": "WEQxbi2veyNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------------------------------\n",
        "## Decision Tree Classifier Model"
      ],
      "metadata": {
        "id": "lkOybQ9ReyNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a decision tree classifier without Feature Engineering\n",
        "\n",
        "X_dense = X_train.toarray()\n",
        "X_val_dense = X_val.toarray()\n",
        "\n",
        "clf = DecisionTreeClassifier(criterion = 'gini',max_depth = 5, min_samples_split= 5, min_samples_leaf= 2)\n",
        "\n",
        "# Train the model on the data\n",
        "clf.fit(X_dense, y_train_single_label)\n",
        "\n",
        "# Use the model for prediction\n",
        "predictions = clf.predict(X_val_dense)\n",
        "\n",
        "# Get unique original labels\n",
        "original_labels = np.unique(y_train)\n",
        "\n",
        "# Create mapping\n",
        "label_mapping = {i: label for i, label in enumerate(original_labels)}\n",
        "\n",
        "# Convert predicted indices to original labels\n",
        "y_pred_tree = [label_mapping[pred] for pred in predictions]\n",
        "\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy_tree = accuracy_score(y_val, y_pred_tree)\n",
        "precision_tree = precision_score(y_val, y_pred_tree, average='weighted')\n",
        "recall_tree = recall_score(y_val, y_pred_tree, average='weighted')\n",
        "f1_tree = f1_score(y_val, y_pred_tree, average='weighted')\n",
        "conf_matrix_tree = confusion_matrix(y_val, y_pred_tree)\n",
        "class_report_tree = classification_report(y_val, y_pred_tree)\n",
        "\n",
        "# Print metrics\n",
        "print(f'Accuracy: {accuracy_tree}')\n",
        "print(f'Precision: {precision_tree}')\n",
        "print(f'Recall: {recall_tree}')\n",
        "print(f'F1 Score: {f1_tree}')\n",
        "print(f'Confusion Matrix:\\n{conf_matrix_tree}')\n",
        "print(f'Classification Report:\\n{class_report_tree}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:15:51.229144Z",
          "iopub.execute_input": "2024-08-10T09:15:51.229564Z",
          "iopub.status.idle": "2024-08-10T09:15:52.811526Z",
          "shell.execute_reply.started": "2024-08-10T09:15:51.229534Z",
          "shell.execute_reply": "2024-08-10T09:15:52.810426Z"
        },
        "trusted": true,
        "id": "VN9KbuGaeyNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a decision tree classifier with Feature Engineering(PCA)\n",
        "\n",
        "clf_PCA = DecisionTreeClassifier()\n",
        "\n",
        "# Train the model on the data\n",
        "clf_PCA.fit(X_train_pca, y_train)\n",
        "\n",
        "# Use the model for prediction\n",
        "predictions = clf_PCA.predict(X_val_pca)\n",
        "\n",
        "# Get unique original labels\n",
        "original_labels = np.unique(y_train)\n",
        "\n",
        "# Create mapping\n",
        "label_mapping = {i: label for i, label in enumerate(original_labels)}\n",
        "\n",
        "# Convert predicted indices to original labels\n",
        "y_pred_tree = [label_mapping[pred] for pred in predictions]\n",
        "\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy_tree_pca = accuracy_score(y_val, y_pred_tree)\n",
        "precision_tree_pca = precision_score(y_val, y_pred_tree, average='weighted')\n",
        "recall_tree_pca = recall_score(y_val, y_pred_tree, average='weighted')\n",
        "f1_tree_pca = f1_score(y_val, y_pred_tree, average='weighted')\n",
        "conf_matrix_tree_pca = confusion_matrix(y_val, y_pred_tree)\n",
        "class_report_tree_pca = classification_report(y_val, y_pred_tree)\n",
        "\n",
        "# Print metrics\n",
        "print(f'Accuracy: {accuracy_tree_pca}')\n",
        "print(f'Precision: {precision_tree_pca}')\n",
        "print(f'Recall: {recall_tree_pca}')\n",
        "print(f'F1 Score: {f1_tree_pca}')\n",
        "print(f'Confusion Matrix:\\n{conf_matrix_tree_pca}')\n",
        "print(f'Classification Report:\\n{class_report_tree_pca}')"
      ],
      "metadata": {
        "trusted": true,
        "id": "0PrxvPkFeyNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a decision tree classifier with Feature Engineering(SelectKBest)\n",
        "\n",
        "clf_Sel = DecisionTreeClassifier()\n",
        "\n",
        "# Train the model on the data\n",
        "clf_Sel.fit(X_train_selected, y_train)\n",
        "\n",
        "# Use the model for prediction\n",
        "predictions = clf_Sel.predict(X_val_selected)\n",
        "\n",
        "# Assign prediction to y_pred_tree\n",
        "y_pred_tree = predictions\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy_tree_val = accuracy_score(y_val, y_pred_tree)\n",
        "precision_tree_val = precision_score(y_val, y_pred_tree, average='weighted')\n",
        "recall_tree_val = recall_score(y_val, y_pred_tree, average='weighted')\n",
        "f1_tree_val = f1_score(y_val, y_pred_tree, average='weighted')\n",
        "conf_matrix_tree_val = confusion_matrix(y_val, y_pred_tree)\n",
        "class_report_tree_val = classification_report(y_val, y_pred_tree)\n",
        "\n",
        "# Print metrics\n",
        "print(f'Accuracy: {accuracy_tree_val}')\n",
        "print(f'Precision: {precision_tree_val}')\n",
        "print(f'Recall: {recall_tree_val}')\n",
        "print(f'F1 Score: {f1_tree_val}')\n",
        "print(f'Confusion Matrix:\\n{conf_matrix_tree_val}')\n",
        "print(f'Classification Report:\\n{class_report_tree_val}')\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "9pJQYgq1eyNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "mGQG2vCreyNr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bagging Classifier Model"
      ],
      "metadata": {
        "id": "KrDZE4TJeyNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Bagging Classifier(RandomForest) without Feature Engineering\n",
        "\n",
        "class BaseModel(BaseEstimator):\n",
        "    def fit(self, X_train, y_train_single_label):\n",
        "\n",
        "        pass\n",
        "\n",
        "    def predict(self, X_train):\n",
        "\n",
        "        pass\n",
        "\n",
        "base_estimator = DecisionTreeClassifier()\n",
        "\n",
        "n_estimators = 100\n",
        "\n",
        "bagging_model = BaggingClassifier(base_estimator=base_estimator, n_estimators=n_estimators)\n",
        "\n",
        "bagging_model.fit(X_train, y_train_single_label)\n",
        "\n",
        "predictions_bagging = bagging_model.predict(X_val)\n",
        "\n",
        "# Get unique original labels (replace y_train with your original label array)\n",
        "original_labels = np.unique(y_train)\n",
        "\n",
        "# Create mapping\n",
        "label_mapping = {i: label for i, label in enumerate(original_labels)}\n",
        "\n",
        "# Convert predicted indices to original labels\n",
        "y_pred_bagging = [label_mapping[pred] for pred in predictions_bagging]\n",
        "\n",
        "# Bagging Valiadation Metrics\n",
        "\n",
        "accuracy_bag = accuracy_score(y_val, y_pred_bagging)\n",
        "precision_bag = precision_score(y_val, y_pred_bagging, average='weighted')\n",
        "recall_bag = recall_score(y_val, y_pred_bagging, average='weighted')\n",
        "f1_bag = f1_score(y_val, y_pred_bagging, average='weighted')\n",
        "cm_bag = confusion_matrix(y_val, y_pred_bagging)\n",
        "roc_auc_bag = roc_auc_score(y_val, bagging_model.predict_proba(X_val), multi_class='ovr')\n",
        "\n",
        "print(f\"Accuracy: {accuracy_bag:.4f}\")\n",
        "print(f\"Precision: {precision_bag:.4f}\")\n",
        "print(f\"Recall: {recall_bag:.4f}\")\n",
        "print(f\"F1 Score: {f1_bag:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm_bag)\n",
        "print(f\"ROC-AUC: {roc_auc_bag:.4f}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:16:10.437068Z",
          "iopub.execute_input": "2024-08-10T09:16:10.43747Z",
          "iopub.status.idle": "2024-08-10T09:17:03.472698Z",
          "shell.execute_reply.started": "2024-08-10T09:16:10.437439Z",
          "shell.execute_reply": "2024-08-10T09:17:03.471615Z"
        },
        "trusted": true,
        "id": "QMuygUwJeyNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Bagging Classifier with Feature Engineering(PCA)\n",
        "\n",
        "class BaseModel(BaseEstimator):\n",
        "    def fit(self, X_train_pca, y_train_single_label):\n",
        "\n",
        "        pass\n",
        "\n",
        "    def predict(self, X_train_pca):\n",
        "\n",
        "        pass\n",
        "\n",
        "base_estimator = DecisionTreeClassifier()\n",
        "\n",
        "n_estimators = 100\n",
        "\n",
        "bagging_model = BaggingClassifier(base_estimator=base_estimator, n_estimators=n_estimators)\n",
        "\n",
        "bagging_model.fit(X_train_pca, y_train_single_label)\n",
        "\n",
        "predictions_bagging = bagging_model.predict(X_val_pca)\n",
        "\n",
        "# Get unique original labels (replace y_train with your original label array)\n",
        "original_labels = np.unique(y_train)\n",
        "\n",
        "# Create mapping\n",
        "label_mapping = {i: label for i, label in enumerate(original_labels)}\n",
        "\n",
        "# Convert predicted indices to original labels\n",
        "y_pred_bagging = [label_mapping[pred] for pred in predictions_bagging]\n",
        "\n",
        "# Bagging Valiadation Metrics\n",
        "\n",
        "accuracy_bagging = accuracy_score(y_val, y_pred_bagging)\n",
        "precision_bagging = precision_score(y_val, y_pred_bagging, average='weighted')\n",
        "recall_bagging = recall_score(y_val, y_pred_bagging, average='weighted')\n",
        "f1_bagging = f1_score(y_val, y_pred_bagging, average='weighted')\n",
        "cm_bagging = confusion_matrix(y_val, y_pred_bagging)\n",
        "roc_auc_bagging = roc_auc_score(y_val, bagging_model.predict_proba(X_val_pca), multi_class='ovr')\n",
        "\n",
        "print(f\"Accuracy: {accuracy_bagging:.4f}\")\n",
        "print(f\"Precision: {precision_bagging:.4f}\")\n",
        "print(f\"Recall: {recall_bagging:.4f}\")\n",
        "print(f\"F1 Score: {f1_bagging:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm_bagging)\n",
        "print(f\"ROC-AUC: {roc_auc_bagging:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "nVEzWbDkeyNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Bagging Classifier with Feature Engineering (SelectKBest)\n",
        "\n",
        "class BaseModel(BaseEstimator):\n",
        "    def fit(self, X_train_selected, y_train_single_label):\n",
        "\n",
        "        pass\n",
        "\n",
        "    def predict(self, X_train_selected):\n",
        "\n",
        "        pass\n",
        "\n",
        "base_estimator = DecisionTreeClassifier()\n",
        "\n",
        "n_estimators = 100\n",
        "\n",
        "bagging_model = BaggingClassifier(base_estimator=base_estimator, n_estimators=n_estimators)\n",
        "\n",
        "bagging_model.fit(X_train_selected, y_train_single_label)\n",
        "\n",
        "predictions_bagging = bagging_model.predict(X_val_selected)\n",
        "\n",
        "# Get unique original labels (replace y_train with your original label array)\n",
        "original_labels = np.unique(y_train)\n",
        "\n",
        "# Create mapping\n",
        "label_mapping = {i: label for i, label in enumerate(original_labels)}\n",
        "\n",
        "# Convert predicted indices to original labels\n",
        "y_pred_bagging = [label_mapping[pred] for pred in predictions_bagging]\n",
        "\n",
        "# Bagging Valiadation Metrics\n",
        "\n",
        "accuracy_bagging = accuracy_score(y_val, y_pred_bagging)\n",
        "precision_bagging = precision_score(y_val, y_pred_bagging, average='weighted')\n",
        "recall_bagging = recall_score(y_val, y_pred_bagging, average='weighted')\n",
        "f1_bagging = f1_score(y_val, y_pred_bagging, average='weighted')\n",
        "cm_bagging = confusion_matrix(y_val, y_pred_bagging)\n",
        "roc_auc_bagging = roc_auc_score(y_val, bagging_model.predict_proba(X_val_selected), multi_class='ovr')\n",
        "\n",
        "print(f\"Accuracy: {accuracy_bagging:.4f}\")\n",
        "print(f\"Precision: {precision_bagging:.4f}\")\n",
        "print(f\"Recall: {recall_bagging:.4f}\")\n",
        "print(f\"F1 Score: {f1_bagging:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm_bagging)\n",
        "print(f\"ROC-AUC: {roc_auc_bagging:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "VuWUmcc9eyNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Vmm4y8pKeyNs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi Layer Perceptron Classifier"
      ],
      "metadata": {
        "id": "eKGEpt5HeyNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create MLPClassifier without Feature Engineering\n",
        "\n",
        "mlp = MLPClassifier(random_state=42)\n",
        "\n",
        "mlp.set_params(hidden_layer_sizes=(100, 50), activation='relu', solver='adam')\n",
        "\n",
        "mlp.fit(X_train, y_train_single_label)\n",
        "\n",
        "predictions_mlp = mlp.predict(X_val)\n",
        "\n",
        "\n",
        "# Get unique original labels\n",
        "original_labels = np.unique(y_train)\n",
        "\n",
        "# Create mapping\n",
        "label_mapping = {i: label for i, label in enumerate(original_labels)}\n",
        "\n",
        "# Convert predicted indices to original labels\n",
        "y_pred_mlp = [label_mapping[pred] for pred in predictions_mlp]\n",
        "\n",
        "# MLPClassifier Valiadation Metrics\n",
        "\n",
        "accuracy_mlp1 = accuracy_score(y_val, y_pred_mlp)\n",
        "precision_mlp = precision_score(y_val, y_pred_mlp, average='weighted')\n",
        "recall_mlp = recall_score(y_val, y_pred_mlp, average='weighted')\n",
        "f1_mlp = f1_score(y_val, y_pred_mlp, average='weighted')\n",
        "cm_mlp = confusion_matrix(y_val, y_pred_mlp)\n",
        "roc_auc_mlp = roc_auc_score(y_val, mlp.predict_proba(X_val), multi_class='ovr')\n",
        "\n",
        "print(f\"Accuracy: {accuracy_mlp1:.4f}\")\n",
        "print(f\"Precision: {precision_mlp:.4f}\")\n",
        "print(f\"Recall: {recall_mlp:.4f}\")\n",
        "print(f\"F1 Score: {f1_mlp:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm_mlp)\n",
        "print(f\"ROC-AUC: {roc_auc_mlp:.4f}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:18:58.883548Z",
          "iopub.execute_input": "2024-08-10T09:18:58.883986Z",
          "iopub.status.idle": "2024-08-10T09:19:48.345553Z",
          "shell.execute_reply.started": "2024-08-10T09:18:58.883935Z",
          "shell.execute_reply": "2024-08-10T09:19:48.344358Z"
        },
        "trusted": true,
        "id": "NAamd6EKeyNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create MLPClassifier with Feature Engineering(SelectKBest)\n",
        "\n",
        "mlp = MLPClassifier(random_state=42)\n",
        "\n",
        "mlp.set_params(hidden_layer_sizes=(100, 50), activation='relu', solver='adam')\n",
        "\n",
        "mlp.fit(X_train_selected, y_train_single_label)\n",
        "\n",
        "predictions_mlp = mlp.predict(X_val_selected)\n",
        "\n",
        "\n",
        "# Get unique original labels\n",
        "original_labels = np.unique(y_train)\n",
        "\n",
        "# Create mapping\n",
        "label_mapping = {i: label for i, label in enumerate(original_labels)}\n",
        "\n",
        "# Convert predicted indices to original labels\n",
        "y_pred_mlp = [label_mapping[pred] for pred in predictions_mlp]\n",
        "\n",
        "# MLPClassifier Valiadation Metrics\n",
        "\n",
        "accuracy_mlp = accuracy_score(y_val, y_pred_mlp)\n",
        "precision_mlp = precision_score(y_val, y_pred_mlp, average='weighted')\n",
        "recall_mlp = recall_score(y_val, y_pred_mlp, average='weighted')\n",
        "f1_mlp = f1_score(y_val, y_pred_mlp, average='weighted')\n",
        "cm_mlp = confusion_matrix(y_val, y_pred_mlp)\n",
        "roc_auc_mlp = roc_auc_score(y_val, mlp.predict_proba(X_val_selected), multi_class='ovr')\n",
        "\n",
        "print(f\"Accuracy: {accuracy_mlp:.4f}\")\n",
        "print(f\"Precision: {precision_mlp:.4f}\")\n",
        "print(f\"Recall: {recall_mlp:.4f}\")\n",
        "print(f\"F1 Score: {f1_mlp:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm_mlp)\n",
        "print(f\"ROC-AUC: {roc_auc_mlp:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "P-pDpxN0eyNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create MLPClassifier with Feature Engineering(PCA)\n",
        "\n",
        "mlp = MLPClassifier(random_state=42)\n",
        "\n",
        "mlp.set_params(hidden_layer_sizes=(100, 50), activation='relu', solver='adam')\n",
        "\n",
        "mlp.fit(X_train_pca, y_train_single_label)\n",
        "\n",
        "predictions_mlp = mlp.predict(X_val_pca)\n",
        "\n",
        "\n",
        "# Get unique original labels\n",
        "original_labels = np.unique(y_train)\n",
        "\n",
        "# Create mapping\n",
        "label_mapping = {i: label for i, label in enumerate(original_labels)}\n",
        "\n",
        "# Convert predicted indices to original labels\n",
        "y_pred_mlp = [label_mapping[pred] for pred in predictions_mlp]\n",
        "\n",
        "# MLPClassifier Valiadation Metrics\n",
        "\n",
        "accuracy_mlp = accuracy_score(y_val, y_pred_mlp)\n",
        "precision_mlp = precision_score(y_val, y_pred_mlp, average='weighted')\n",
        "recall_mlp = recall_score(y_val, y_pred_mlp, average='weighted')\n",
        "f1_mlp = f1_score(y_val, y_pred_mlp, average='weighted')\n",
        "cm_mlp = confusion_matrix(y_val, y_pred_mlp)\n",
        "roc_auc_mlp = roc_auc_score(y_val, mlp.predict_proba(X_val_pca), multi_class='ovr')\n",
        "\n",
        "print(f\"Accuracy: {accuracy_mlp:.4f}\")\n",
        "print(f\"Precision: {precision_mlp:.4f}\")\n",
        "print(f\"Recall: {recall_mlp:.4f}\")\n",
        "print(f\"F1 Score: {f1_mlp:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm_mlp)\n",
        "print(f\"ROC-AUC: {roc_auc_mlp:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "bY21s2EeeyNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Gradient Boosting Classifier"
      ],
      "metadata": {
        "id": "L1aAy96_eyNs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyper Parameter Tuning for Gradient Boosting Classifier"
      ],
      "metadata": {
        "id": "2dVA5DJReyNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import randint\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': randint(200, 300),\n",
        "    'learning_rate': [0.05, 0.01],\n",
        "    'max_depth': randint(4, 6)\n",
        "}\n",
        "\n",
        "GBCmodel = GradientBoostingClassifier()\n",
        "GBCrandom_search = RandomizedSearchCV(estimator=GBCmodel, param_distributions=param_dist, n_iter=3, cv=5, scoring='accuracy')\n",
        "GBCrandom_search.fit(X_train_selected, y_train_single_label)\n",
        "\n",
        "\n",
        "# Get the best model and parameters for Gradient Boosting Class\n",
        "GBCbest_model = GBCrandom_search.best_estimator_\n",
        "GBCbest_params = GBCrandom_search.best_params_\n",
        "GBCbest_score = GBCrandom_search.best_score_\n",
        "\n",
        "print(GBCbest_model)\n",
        "print(GBCbest_params)\n",
        "print(GBCbest_score)"
      ],
      "metadata": {
        "trusted": true,
        "id": "gIZpFjNeeyNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Result** :\n",
        "\n",
        "After doing RandomSearchCV these were the best parameters obtained.\n",
        "\n",
        "\n",
        "GradientBoostingClassifier(learning_rate=0.01, max_depth=5, n_estimators=273)\n",
        "\n",
        "\n",
        "{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 273}\n"
      ],
      "metadata": {
        "id": "nnlk-wnseyNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Boosting Classifier Model for Validation"
      ],
      "metadata": {
        "id": "0eV82J6eeyNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Boosting without Feature Engineering\n",
        "\n",
        "best_gbc = GradientBoostingClassifier(learning_rate=0.01, max_depth=5, n_estimators=273,random_state=42)\n",
        "\n",
        "best_gbc.fit(X_train, y_train_single_label)\n",
        "\n",
        "# Use the model for prediction\n",
        "predictions_GBC = best_gbc.predict(X_val)\n",
        "\n",
        "# Get unique original labels\n",
        "original_labels = np.unique(y_train)\n",
        "\n",
        "# Create mapping\n",
        "label_mapping = {i: label for i, label in enumerate(original_labels)}\n",
        "\n",
        "# Convert predicted indices to original labels\n",
        "y_pred_GBC = [label_mapping[pred] for pred in predictions_GBC]\n",
        "\n",
        "# calculating Validation Metrics for GradientBoostingClassifier\n",
        "\n",
        "GBCaccuracy = accuracy_score(y_val_single_label, predictions_GBC)\n",
        "GBCprecision = precision_score(y_val_single_label, predictions_GBC,average='weighted')\n",
        "GBCrecall = recall_score(y_val_single_label, predictions_GBC,average='weighted')\n",
        "GBCf1 = f1_score(y_val_single_label, predictions_GBC,average='weighted')\n",
        "GBCconf_matrix = confusion_matrix(y_val_single_label, predictions_GBC)\n",
        "cm_GBC = confusion_matrix(y_val, y_pred_GBC)\n",
        "roc_auc_GBC = roc_auc_score(y_val, best_gbc.predict_proba(X_val), multi_class='ovr')\n",
        "\n",
        "print(\"Accuracy:\", GBCaccuracy)\n",
        "print(\"Precision:\", GBCprecision)\n",
        "print(\"Recall:\", GBCrecall)\n",
        "print(\"F1-score:\", GBCf1)\n",
        "print(\"Confusion Matrix:\\n\", GBCconf_matrix)\n",
        "print(cm_GBC)\n",
        "print(f\"ROC-AUC: {roc_auc_GBC:.4f}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:24:48.037708Z",
          "iopub.execute_input": "2024-08-10T09:24:48.038183Z",
          "iopub.status.idle": "2024-08-10T09:27:35.44806Z",
          "shell.execute_reply.started": "2024-08-10T09:24:48.038144Z",
          "shell.execute_reply": "2024-08-10T09:27:35.446879Z"
        },
        "trusted": true,
        "id": "yYZyTi99eyNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Boosting with Feature Engineering (SelectKBest)\n",
        "\n",
        "best_gbc = GradientBoostingClassifier(learning_rate=0.01, max_depth=5, n_estimators=273,random_state=42)\n",
        "\n",
        "best_gbc.fit(X_train_selected, y_train_single_label)\n",
        "\n",
        "# Use the model for prediction\n",
        "predictions_GBC = best_gbc.predict(X_val_selected)\n",
        "\n",
        "# Get unique original labels\n",
        "original_labels = np.unique(y_train)\n",
        "\n",
        "# Create mapping\n",
        "label_mapping = {i: label for i, label in enumerate(original_labels)}\n",
        "\n",
        "# Convert predicted indices to original labels\n",
        "y_pred_GBC = [label_mapping[pred] for pred in predictions_GBC]\n",
        "\n",
        "# calculating Validation Metrics for GradientBoostingClassifier\n",
        "\n",
        "GBCaccuracy = accuracy_score(y_val_single_label, predictions_GBC)\n",
        "GBCprecision = precision_score(y_val_single_label, predictions_GBC,average='weighted')\n",
        "GBCrecall = recall_score(y_val_single_label, predictions_GBC,average='weighted')\n",
        "GBCf1 = f1_score(y_val_single_label, predictions_GBC,average='weighted')\n",
        "GBCconf_matrix = confusion_matrix(y_val_single_label, predictions_GBC)\n",
        "cm_GBC = confusion_matrix(y_val, y_pred_GBC)\n",
        "roc_auc_GBC = roc_auc_score(y_val, best_gbc.predict_proba(X_val_selected), multi_class='ovr')\n",
        "\n",
        "print(\"Accuracy:\", GBCaccuracy)\n",
        "print(\"Precision:\", GBCprecision)\n",
        "print(\"Recall:\", GBCrecall)\n",
        "print(\"F1-score:\", GBCf1)\n",
        "print(\"Confusion Matrix:\\n\", GBCconf_matrix)\n",
        "print(cm_GBC)\n",
        "print(f\"ROC-AUC: {roc_auc_GBC:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "ipRBtckDeyNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Boosting with Feature Engineering(PCA)\n",
        "\n",
        "best_gbc = GradientBoostingClassifier(learning_rate=0.01, max_depth=5, n_estimators=273,random_state=42)\n",
        "\n",
        "best_gbc.fit(X_train_pca, y_train_single_label)\n",
        "\n",
        "# Use the model for prediction\n",
        "predictions_GBC = best_gbc.predict(X_val_pca)\n",
        "\n",
        "# Get unique original labels\n",
        "original_labels = np.unique(y_train)\n",
        "\n",
        "# Create mapping\n",
        "label_mapping = {i: label for i, label in enumerate(original_labels)}\n",
        "\n",
        "# Convert predicted indices to original labels\n",
        "y_pred_GBC = [label_mapping[pred] for pred in predictions_GBC]\n",
        "\n",
        "# calculating Validation Metrics for GradientBoostingClassifier\n",
        "\n",
        "GBCaccuracy = accuracy_score(y_val_single_label, predictions_GBC)\n",
        "GBCprecision = precision_score(y_val_single_label, predictions_GBC,average='weighted')\n",
        "GBCrecall = recall_score(y_val_single_label, predictions_GBC,average='weighted')\n",
        "GBCf1 = f1_score(y_val_single_label, predictions_GBC,average='weighted')\n",
        "GBCconf_matrix = confusion_matrix(y_val_single_label, predictions_GBC)\n",
        "cm_GBC = confusion_matrix(y_val, y_pred_GBC)\n",
        "roc_auc_GBC = roc_auc_score(y_val, best_gbc.predict_proba(X_val_pca), multi_class='ovr')\n",
        "\n",
        "print(\"Accuracy:\", GBCaccuracy)\n",
        "print(\"Precision:\", GBCprecision)\n",
        "print(\"Recall:\", GBCrecall)\n",
        "print(\"F1-score:\", GBCf1)\n",
        "print(\"Confusion Matrix:\\n\", GBCconf_matrix)\n",
        "print(cm_GBC)\n",
        "print(f\"ROC-AUC: {roc_auc_GBC:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "7_7uyOMSeyNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------------"
      ],
      "metadata": {
        "id": "rZ9XhQ09eyNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample model names and performance metrics (accuracy)\n",
        "model_names = [\"Logistic Reg\", \"KNN\", \"Decision Tree\", \"Random Forest\", \"MLPC\",\"Gradient Boosting\"]\n",
        "accuracy_scores = [accuracy_Log,accuracy_knn,accuracy_tree,accuracy_bag,accuracy_mlp1,GBCaccuracy]\n",
        "\n",
        "# Create a bar chart\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.barh(model_names, accuracy_scores, color=['blue', 'green', 'orange', 'red','purple','yellow'])\n",
        "plt.xlabel(\"Model Name\")\n",
        "plt.ylabel(\"Accuracy Score\")\n",
        "plt.title(\"Model Performance Comparison\")\n",
        "plt.xticks(rotation=45, ha=\"right\")  # Rotate x-axis labels for better readability\n",
        "\n",
        "# Display the chart\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:37:18.828438Z",
          "iopub.execute_input": "2024-08-10T09:37:18.829404Z",
          "iopub.status.idle": "2024-08-10T09:37:19.193803Z",
          "shell.execute_reply.started": "2024-08-10T09:37:18.82936Z",
          "shell.execute_reply": "2024-08-10T09:37:19.192611Z"
        },
        "trusted": true,
        "id": "hX5jr2UkeyNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Boosting Classifier Model (Best Model submitted for Predictions)"
      ],
      "metadata": {
        "id": "Yc1nKnJMeyNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Boosting Classifier Model run with train and test datasets and submitted the predictions to competition\n",
        "\n",
        "best_gbc = GradientBoostingClassifier(learning_rate=0.01, max_depth=5, n_estimators=273,random_state=42)\n",
        "\n",
        "best_gbc.fit(train_encoded, y_single_label)\n",
        "\n",
        "# Use the model for prediction\n",
        "predictions_GBC = best_gbc.predict(test_encoded)\n",
        "\n",
        "# Get unique original labels (replace y_train with your original label array)\n",
        "original_labels = np.unique(y)\n",
        "\n",
        "# Create mapping\n",
        "label_mapping = {i: label for i, label in enumerate(original_labels)}\n",
        "\n",
        "# Convert predicted indices to original labels\n",
        "y_pred_GBC = [label_mapping[pred] for pred in predictions_GBC]\n",
        "\n",
        "#How to make a Submission this is the code one should type\n",
        "submission = pd.DataFrame({\"ID\":np.arange(1,5001),\n",
        "                           \"Crime_Category\": y_pred_GBC,\n",
        "                            })\n",
        "submission.to_csv('/kaggle/working/submission.csv',index = False)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-10T09:30:49.358632Z",
          "iopub.execute_input": "2024-08-10T09:30:49.359059Z",
          "iopub.status.idle": "2024-08-10T09:34:55.299245Z",
          "shell.execute_reply.started": "2024-08-10T09:30:49.359019Z",
          "shell.execute_reply": "2024-08-10T09:34:55.297587Z"
        },
        "trusted": true,
        "id": "ZLWg61H8eyNu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}